{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_bert.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMF8WmfLHIpZSVU1VYQs7Kk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e313b623bb5f4d62aab564351c74de15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_455a74c365d14d26bd0de849cad5bd3f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e571897107314c258e90eac257761629",
              "IPY_MODEL_33fcc891a7304737a8c913fed48c5836"
            ]
          }
        },
        "455a74c365d14d26bd0de849cad5bd3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e571897107314c258e90eac257761629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_799095f314ff4a48a2d314f46246b8ee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_738ea05f48b5421da45b90f438c2ac0a"
          }
        },
        "33fcc891a7304737a8c913fed48c5836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3eebbe9634ba49f3aeed6e95323747b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 50.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bf252de356b42e4aec12c1d541b5ea9"
          }
        },
        "799095f314ff4a48a2d314f46246b8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "738ea05f48b5421da45b90f438c2ac0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3eebbe9634ba49f3aeed6e95323747b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bf252de356b42e4aec12c1d541b5ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff36b21afec148e7b6826c2420682b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33a5e646a1e543d4953c6aa9e414660e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34b1394206a94da3991a1a2791a5589b",
              "IPY_MODEL_a398755f002547ae885ac17b3f827967"
            ]
          }
        },
        "33a5e646a1e543d4953c6aa9e414660e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34b1394206a94da3991a1a2791a5589b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57e96c3883ea40bfa192cede23ce49f3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfdaaec86da14d298dd18838675194b9"
          }
        },
        "a398755f002547ae885ac17b3f827967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_72c4a312d41145ccbade23ab40148ba6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 43.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc00d290c9ae47c9be280678e43b1a3f"
          }
        },
        "57e96c3883ea40bfa192cede23ce49f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfdaaec86da14d298dd18838675194b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72c4a312d41145ccbade23ab40148ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc00d290c9ae47c9be280678e43b1a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fawazshah/News-Media-Reliability/blob/master/train_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v3OZRfOXciF"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WdkCXGSlBCD"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH89boyR8xMe"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import requests\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import time\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvijqpDgSdrG"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdQJh_Gspywv"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ltm1AzQ5P2p"
      },
      "source": [
        "corpus_url = 'https://raw.githubusercontent.com/fawazshah/News-Media-Reliability/master/data/emnlp18/corpus-modified.tsv'\n",
        "\n",
        "corpus = pd.read_csv(corpus_url, sep='\\t')\n",
        "urls = corpus['source_url_normalized'].values\n",
        "\n",
        "# Ground truths\n",
        "biases = corpus['bias'].values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aljGD_19QdV"
      },
      "source": [
        "article_data_json_url = 'https://raw.githubusercontent.com/fawazshah/News-Media-Reliability/master/data/scraped_articles.json'\n",
        "\n",
        "r = requests.get(article_data_json_url)\n",
        "article_data = r.json()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcqkrRXyw58K"
      },
      "source": [
        "all_data_df = pd.DataFrame(columns=['article headline', 'article body', 'bias'])\n",
        "\n",
        "news_sources_scraped = 0\n",
        "\n",
        "for row in corpus.itertuples():\n",
        "    url = row.source_url_normalized\n",
        "    bias = row.bias\n",
        "    if article_data[\"newspapers\"][url] is not None:\n",
        "        articles = article_data[\"newspapers\"][url].get(\"articles\", [])\n",
        "        if len(articles) > 0:\n",
        "            news_sources_scraped += 1\n",
        "            for article in articles:\n",
        "                all_data_df = all_data_df.append({'article headline': article['title'],\n",
        "                                                  'article body': article['text'],\n",
        "                                                  'bias': bias}, ignore_index=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "o8iAM1Mb1-Mr",
        "outputId": "0ef589be-1b58-4721-d6d3-1467d7c19821"
      },
      "source": [
        "all_data_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>On the Ground at the Inauguration: The Only Th...</td>\n",
              "      <td>Will Sennott\\n\\nWEDNESDAY, JANUARY 20, 2021, W...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Under President Biden, Will the Yankees Return...</td>\n",
              "      <td>Thurman Munson and Reggie Jackson in 1977 From...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gun Rights Absolutists Celebrate Martin Luther...</td>\n",
              "      <td>Will Sennott\\n\\nMONDAY, JANUARY 18, 2021, RICH...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thugs in Blue</td>\n",
              "      <td>THE BEAT GOES ON … AND ON\\n\\nOnce Again, Polic...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HELL YEAH! Sheriff Clark Publicly DISEMBOWELS ...</td>\n",
              "      <td>Al Sharpton always has had a couple screws loo...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1649</th>\n",
              "      <td>UK Educators Rank-and-File Safety Committee di...</td>\n",
              "      <td>The UK Educators Rank-and-File Safety Committe...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650</th>\n",
              "      <td>Make It Sing</td>\n",
              "      <td>Before I lay into the Democrats for missed opp...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1651</th>\n",
              "      <td>Bill Maher: The SPIN Interview</td>\n",
              "      <td>If you care at all about democracy and the way...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1652</th>\n",
              "      <td>Stephan Jenkins on What Culture Truly Means</td>\n",
              "      <td>“When bad men combine, the good must associate...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1653</th>\n",
              "      <td>Emergence Is Interactive: A Jeff Bridges and S...</td>\n",
              "      <td>Jeff Bridges is an Academy Award-winning actor...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1654 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       article headline  ...   bias\n",
              "0     On the Ground at the Inauguration: The Only Th...  ...   left\n",
              "1     Under President Biden, Will the Yankees Return...  ...   left\n",
              "2     Gun Rights Absolutists Celebrate Martin Luther...  ...   left\n",
              "3                                         Thugs in Blue  ...   left\n",
              "4     HELL YEAH! Sheriff Clark Publicly DISEMBOWELS ...  ...  right\n",
              "...                                                 ...  ...    ...\n",
              "1649  UK Educators Rank-and-File Safety Committee di...  ...   left\n",
              "1650                                       Make It Sing  ...   left\n",
              "1651                     Bill Maher: The SPIN Interview  ...   left\n",
              "1652        Stephan Jenkins on What Culture Truly Means  ...   left\n",
              "1653  Emergence Is Interactive: A Jeff Bridges and S...  ...   left\n",
              "\n",
              "[1654 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3tI0VYup1RN"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx8wTRfPI5jm",
        "outputId": "10e3a3a6-3f83-4def-953b-247e1efbc423"
      },
      "source": [
        "# Text preprocessing preparation\n",
        "\n",
        "stop_words = [\"the\", \"a\", \"an\", \"as\", \"this\", \"that\", \"is\", \"and\", \"or\", \"on\",\n",
        "              \"at\", \"to\", \"in\", \"by\", \"than\", \"of\", \"for\", \"be\", \"i\", \"you\", \n",
        "              \"he\", \"she\", \"his\", \"her\", \"do\", \"it\", \"with\"]\n",
        "\n",
        "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:          \n",
        "        return None\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# required for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# required for POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_vUJWRoo8uy"
      },
      "source": [
        "# Text preprocessing performed on both article headline and article body\n",
        "\n",
        "def preprocess(sentence):\n",
        "\n",
        "    # Lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # Punctuation, whitespace removal\n",
        "    punctuations = '''!()-—[]{};:'\"“”‘’\\,<>./?@#$%^&*_~'''\n",
        "    whitespace = '''\\n\\t'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in punctuations: \n",
        "            sentence = sentence.replace(ch, \"\")\n",
        "        if ch in whitespace:\n",
        "            sentence = sentence.replace(ch, \" \")\n",
        "\n",
        "    # Stop word removal\n",
        "    remaining_words = []\n",
        "    \n",
        "    for word in sentence.split():\n",
        "        if word not in stop_words:\n",
        "            remaining_words.append(word)\n",
        "\n",
        "    sentence = \" \".join(remaining_words)\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_words = []\n",
        "\n",
        "    # In order to lemmatise we must first POS-tag each sentence\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    for word, tag in tagged:\n",
        "        pos = nltk_tag_to_wordnet_tag(tag) \n",
        "        if pos is not None:\n",
        "            word = lemmatizer.lemmatize(word, pos=pos)\n",
        "\n",
        "        lemmatized_words.append(word)\n",
        "\n",
        "    sentence = \" \".join(lemmatized_words)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U6E9s6rRbxK",
        "outputId": "14537ca6-47dd-474b-f637-6b1280cedec3"
      },
      "source": [
        "start = time.time()\n",
        "all_data_df['article headline'] = all_data_df['article headline'].apply(preprocess)\n",
        "print(f\"Preprocessing headlines took {time.time() - start} seconds\")\n",
        "\n",
        "start = time.time()\n",
        "all_data_df['article body'] = all_data_df['article body'].apply(preprocess)\n",
        "print(f\"Preprocessing article bodies took {time.time() - start} seconds\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing headlines took 3.1434688568115234 seconds\n",
            "Preprocessing article bodies took 62.121830701828 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "nlw6MBB_lsoV",
        "outputId": "8f673013-c2f8-43f3-cf7f-d5eb966b2c19"
      },
      "source": [
        "# Randomly shuffle rows in dataset before splitting into folds\n",
        "all_data_df = all_data_df.sample(frac=1, random_state=1)\n",
        "all_data_df.reset_index(drop=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bidens america one nation us versus them</td>\n",
              "      <td>president joe biden sworn 46th president janua...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how get covid19 vaccine miamidade broward</td>\n",
              "      <td>keep new time free support us local community ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>arm mob storm capitol building during electora...</td>\n",
              "      <td>day will go down infamy arm mob storm united s...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frontier ebook release january 2021</td>\n",
              "      <td>download month new release include late specia...</td>\n",
              "      <td>center</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>change date vaccine news angry cricket coach</td>\n",
              "      <td>clancy overell wendell hussey kick off another...</td>\n",
              "      <td>center</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1649</th>\n",
              "      <td>legal liability loom orgs behind rally incite ...</td>\n",
              "      <td>legal liability loom orgs behind rally incite ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650</th>\n",
              "      <td>merck france pasteur institute end development...</td>\n",
              "      <td>covid19 pandemic underscore need our company o...</td>\n",
              "      <td>center</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1651</th>\n",
              "      <td>anthony mackie responsibility message captain ...</td>\n",
              "      <td>anthony mackie clear not all say he new captai...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1652</th>\n",
              "      <td>union just get rare bit good news from supreme...</td>\n",
              "      <td>supreme court announce monday will not hear bl...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1653</th>\n",
              "      <td>florida new hq maga movement</td>\n",
              "      <td>former president donald trump remain iffy 2024...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1654 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       article headline  ...    bias\n",
              "0              bidens america one nation us versus them  ...   right\n",
              "1             how get covid19 vaccine miamidade broward  ...    left\n",
              "2     arm mob storm capitol building during electora...  ...    left\n",
              "3                   frontier ebook release january 2021  ...  center\n",
              "4          change date vaccine news angry cricket coach  ...  center\n",
              "...                                                 ...  ...     ...\n",
              "1649  legal liability loom orgs behind rally incite ...  ...    left\n",
              "1650  merck france pasteur institute end development...  ...  center\n",
              "1651  anthony mackie responsibility message captain ...  ...    left\n",
              "1652  union just get rare bit good news from supreme...  ...    left\n",
              "1653                       florida new hq maga movement  ...   right\n",
              "\n",
              "[1654 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCS4LqNqpw-0"
      },
      "source": [
        "### Splitting data into folds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WVsMZJip6pD"
      },
      "source": [
        "# 5 folds, each with 70% training, 10% validation, 20% train\n",
        "\n",
        "num_folds = 5\n",
        "\n",
        "fold_size = round(len(all_data_df) / num_folds)\n",
        "fold_dfs = [all_data_df.iloc[i*fold_size:(i+1)*fold_size].copy() for i in range(num_folds)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcLgT3JPrI5l"
      },
      "source": [
        "folds = {}\n",
        "\n",
        "for i, df in enumerate(fold_dfs):\n",
        "    folds[i] = {}\n",
        "    split_point_1 = int(0.7*len(df))\n",
        "    split_point_2 = int(0.8*len(df))\n",
        "    folds[i][\"train_df\"] = df.iloc[:split_point_1].copy()\n",
        "    folds[i][\"val_df\"] = df.iloc[split_point_1:split_point_2].copy()\n",
        "    folds[i][\"test_df\"] = df.iloc[split_point_2:].copy()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv18NbamsoT8",
        "outputId": "9cd176c7-d4fd-497b-93ee-e17c27b57f98"
      },
      "source": [
        "print(f\"Number of folds: {num_folds}\")\n",
        "print(f\"Size of each training set: {len(folds[0]['train_df'])}\")\n",
        "print(f\"Size of each validation set: {len(folds[0]['val_df'])}\")\n",
        "print(f\"Size of each test set: {len(folds[0]['test_df'])}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of folds: 5\n",
            "Size of each training set: 231\n",
            "Size of each validation set: 33\n",
            "Size of each test set: 67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRvLmb5gjsqW"
      },
      "source": [
        "### BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-qdjK0sTCvE"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "batch_size = 10"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiKVlaUmBs_E",
        "outputId": "4d24ae5e-d7b6-40a1-c6b9-66d365855451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "class BertDataset(Dataset):\n",
        "    def __init__(self, token_ids, token_type_ids, attention_masks, labels):\n",
        "        self.token_ids = token_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        token_id = self.token_ids[idx]\n",
        "        token_type_id = self.token_type_ids[idx]\n",
        "        attention_mask = self.attention_masks[idx]\n",
        "        label = self.labels[idx]\n",
        "        return tuple([token_id, token_type_id, attention_mask, label])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-882bbee4b028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBertDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "noOaI7TwFfO2",
        "outputId": "51c4a00d-4a2c-47d2-defd-a11aa35ba1ce"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-deeadbfc9ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'BertTokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdMOKYheI2rI"
      },
      "source": [
        "# Compute the length of the longest sentence in particular column out of\n",
        "# all train, val and test data\n",
        "def compute_max_length(col_to_encode):\n",
        "\n",
        "  sentences = all_data_df[col_to_encode].values\n",
        "\n",
        "  max_len = 0\n",
        "\n",
        "  for sent in sentences:\n",
        "\n",
        "      # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "      input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "      # Update the maximum sentence length.\n",
        "      max_len = max(max_len, len(input_ids))\n",
        "\n",
        "  return max_len"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLUvQg9tJkxL",
        "outputId": "7b361b66-cc18-47bc-82ee-2798c98816c2"
      },
      "source": [
        "max_len_headline = compute_max_length('article headline')\n",
        "max_len_body = compute_max_length('article body')\n",
        "\n",
        "print(f\"Max headline length across all folds: {max_len_headline}\")\n",
        "print(f\"Max article body length across all folds: {max_len_body}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max headline length across all folds: 103\n",
            "Max article body length across all folds: 14373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47kpzdncrYs_"
      },
      "source": [
        "def create_bert_dataset(fold, df, col_to_encode, max_sequence_len):\n",
        "    # Returns a BertDataset of sequences in col_to_encode column of df, for\n",
        "    # given fold\n",
        "\n",
        "    token_ids = []\n",
        "    token_type_ids = [] # segment ids \n",
        "    attention_masks = []\n",
        "\n",
        "    sentences = df[col_to_encode].values.tolist()\n",
        "    for sent in sentences:\n",
        "        encoding_dict = tokenizer(sent,\n",
        "                                  add_special_tokens=True,\n",
        "                                  max_length=max_sequence_len,\n",
        "                                  padding='max_length',\n",
        "                                  truncation=True,\n",
        "                                  return_token_type_ids = True,\n",
        "                                  return_attention_mask = True,\n",
        "                                  return_tensors = 'pt'\n",
        "                                  )\n",
        "        token_ids.append(encoding_dict['input_ids'])\n",
        "        token_type_ids.append(encoding_dict['token_type_ids'])\n",
        "        attention_masks.append(encoding_dict['attention_mask'])\n",
        "    \n",
        "    token_ids = torch.cat(token_ids, dim=0)\n",
        "    token_type_ids = torch.cat(token_type_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = df['bias'].values\n",
        "    \n",
        "    return BertDataset(token_ids, token_type_ids, attention_masks, labels)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "xefnAsZO59ZV",
        "outputId": "b964ea3b-d025-4105-fcc0-5603a11c4478"
      },
      "source": [
        "dataloaders = {}\n",
        "\n",
        "dataloaders['headlines'] = {}\n",
        "for i in range(num_folds):\n",
        "    dataloaders['headlines'][i] = {}\n",
        "    train_dataset = create_bert_dataset(i, folds[i]['train_df'], 'article headline', max_len_headline)\n",
        "    dataloaders['headlines'][i]['train'] = Dataloader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
        "    val_dataset = create_bert_dataset(i, folds[i]['val_df'], 'article headline', max_len_headline)\n",
        "    dataloaders['headlines'][i]['val'] = Dataloader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n",
        "    test_dataset = create_bert_dataset(i, folds[i]['test_df'], 'article headline', max_len_headline)\n",
        "    dataloaders['headlines'][i]['test'] = Dataloader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
        "\n",
        "dataloaders['bodies'] = {}\n",
        "for i in range(num_folds):\n",
        "    dataloaders['bodies'][i] = {}\n",
        "    train_dataset = create_bert_dataset(i, folds[i]['train_df'], 'article body', max_len_body)\n",
        "    dataloaders['bodies'][i]['train'] = Dataloader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
        "    val_dataset = create_bert_dataset(i, folds[i]['val_df'], 'article body', max_len_body)\n",
        "    dataloaders['bodies'][i]['val'] = Dataloader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n",
        "    test_dataset = create_bert_dataset(i, folds[i]['test_df'], 'article body', max_len_body)\n",
        "    dataloaders['bodies'][i]['test'] = Dataloader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-7ad620941d70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     datasets['headlines'][i]['train'] = create_bert_dataset(i, folds[i]['train_df'],\n\u001b[1;32m      7\u001b[0m                                                             \u001b[0;34m'article headline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                             max_len_headline)\n\u001b[0m\u001b[1;32m      9\u001b[0m     datasets['headlines'][i]['val'] = create_bert_dataset(i, folds[i]['val_df'],\n\u001b[1;32m     10\u001b[0m                                                             \u001b[0;34m'article headline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-8fa83e6c4dbd>\u001b[0m in \u001b[0;36mcreate_bert_dataset\u001b[0;34m(fold, df, col_to_encode, max_sequence_len)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uysrdNBJx0G"
      },
      "source": [
        "def train_BERT(train_dataloader, val_dataloader, model, number_epoch):\n",
        "\n",
        "    train_loss = []\n",
        "    valid_loss = []\n",
        "\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                    lr = 2e-5, \n",
        "                    eps = 1e-8 \n",
        "                )\n",
        "\n",
        "    # Create the learning rate scheduler.\n",
        "    total_steps = len(train_dataloader) * number_epoch\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "\n",
        "        # TRAINING\n",
        "\n",
        "        time0 = time.time()\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        epoch_train_loss = 0\n",
        "        no_observations = 0\n",
        "        epoch_train_predictions = []\n",
        "        epoch_train_labels = []\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "            # Each batch contains, input ids, attention masks and labels\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            no_observations = no_observations + b_labels.shape[0]\n",
        "            \n",
        "            output = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            loss = output.loss\n",
        "            logits = output.logits\n",
        "\n",
        "            predictions = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "            labels = b_labels.detach().cpu().numpy()\n",
        "            epoch_train_predictions.extend(predictions)\n",
        "            epoch_train_labels.extend(labels)\n",
        "\n",
        "            loss.backward()\n",
        "            # Clip the norm of the gradients to 1 to prevent exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step() \n",
        "\n",
        "            # Update the learning rate using the scheduler\n",
        "            scheduler.step()  \n",
        "\n",
        "            epoch_train_loss += loss.item()*b_labels.shape[0]\n",
        "\n",
        "        epoch_train_loss, epoch_train_acc = epoch_train_loss / no_observations, accuracy_score(epoch_train_labels, epoch_train_predictions)\n",
        "\n",
        "        # VALIDATION\n",
        "\n",
        "        epoch_valid_loss, epoch_val_predictions, epoch_val_labels = evaluate_BERT(val_dataloader, model)\n",
        "        epoch_valid_acc = accuracy_score(epoch_val_labels, epoch_val_predictions)\n",
        "\n",
        "        # FINALLY\n",
        "\n",
        "        print(f\"Epoch took: {time.time() - time0}\")\n",
        "\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_train_loss:.2f} | Train Accuracy: {epoch_train_acc:.2f} | \\\n",
        "        Val. Loss: {epoch_valid_loss:.2f} | Val. Accuracy: {epoch_valid_acc:.2f} |')\n",
        "\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        valid_loss.append(epoch_valid_loss)\n",
        "    \n",
        "    return train_loss, valid_loss"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxb6dGkmRLky"
      },
      "source": [
        "def evaluate_BERT(test_dataloader, model):\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    no_observations = 0\n",
        "    predictions_all = []\n",
        "    labels_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iter:\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            no_observations += b_labels.shape[0]\n",
        "            output = model(b_input_ids, token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask)\n",
        "            logits = output.logits\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "\n",
        "            predictions = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "            labels = b_labels.detach().cpu().numpy()\n",
        "            predictions_all.extend(predictions)\n",
        "            labels_all.extend(labels)\n",
        "\n",
        "            total_loss += loss.item()*b_labels.shape[0]\n",
        "    \n",
        "    return total_loss / no_observations, predictions_all, labels_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "e313b623bb5f4d62aab564351c74de15",
            "455a74c365d14d26bd0de849cad5bd3f",
            "e571897107314c258e90eac257761629",
            "33fcc891a7304737a8c913fed48c5836",
            "799095f314ff4a48a2d314f46246b8ee",
            "738ea05f48b5421da45b90f438c2ac0a",
            "3eebbe9634ba49f3aeed6e95323747b9",
            "3bf252de356b42e4aec12c1d541b5ea9",
            "ff36b21afec148e7b6826c2420682b5e",
            "33a5e646a1e543d4953c6aa9e414660e",
            "34b1394206a94da3991a1a2791a5589b",
            "a398755f002547ae885ac17b3f827967",
            "57e96c3883ea40bfa192cede23ce49f3",
            "bfdaaec86da14d298dd18838675194b9",
            "72c4a312d41145ccbade23ab40148ba6",
            "bc00d290c9ae47c9be280678e43b1a3f"
          ]
        },
        "id": "n-AFqf9cQIfz",
        "outputId": "30baffeb-ab7b-471d-f6a9-52c9c6004bc7"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=3,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "for i in range(num_folds):\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e313b623bb5f4d62aab564351c74de15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff36b21afec148e7b6826c2420682b5e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ponCV4YPQ0gl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}