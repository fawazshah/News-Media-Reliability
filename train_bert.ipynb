{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_bert.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN3vjwW+hFnQVHtrtOVpX4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffbe8eb2faad4b50afa48ac768cf1ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_21f02fd6038749d3bd7a8aeb61507f2a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4432b868ea6c4bdcbdf3b00501ef5578",
              "IPY_MODEL_aacc0644b7f54960bc59a268ef1e9db0"
            ]
          }
        },
        "21f02fd6038749d3bd7a8aeb61507f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4432b868ea6c4bdcbdf3b00501ef5578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e190904fd1af47b58b1a29a851bc2fe3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e78d0ef5ddbc4084babcd93fbad5e286"
          }
        },
        "aacc0644b7f54960bc59a268ef1e9db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_02efdba765f44740a88adec3be2ef57b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.96MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98da849b315f4a9198f507279c162759"
          }
        },
        "e190904fd1af47b58b1a29a851bc2fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e78d0ef5ddbc4084babcd93fbad5e286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02efdba765f44740a88adec3be2ef57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98da849b315f4a9198f507279c162759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d6de272bc3b4b9d8d64a44cbcd5f266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b310a445d5d147c1a5ebadafecf5b6f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a4ae115b3c694b9ebe5c3573d52a2651",
              "IPY_MODEL_a65df974359e47a8b8273934ea00aeaf"
            ]
          }
        },
        "b310a445d5d147c1a5ebadafecf5b6f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4ae115b3c694b9ebe5c3573d52a2651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ba493ea05d24a2a95f0a385efbcdcda",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3fe16931764493aaecbf31e18b62245"
          }
        },
        "a65df974359e47a8b8273934ea00aeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bba7a6b2be794e8e9a2f732e1e69e640",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:58&lt;00:00, 7.41B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b0d83d8d0f344ac8c1dd827635336eb"
          }
        },
        "4ba493ea05d24a2a95f0a385efbcdcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3fe16931764493aaecbf31e18b62245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bba7a6b2be794e8e9a2f732e1e69e640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b0d83d8d0f344ac8c1dd827635336eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4720716c0f7e4eeb9f0b3fac4ad68d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6150b47362c644baa5c6a8391038cc3e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1cc1cf2e9cc4a90aae2e74d29fb06f4",
              "IPY_MODEL_8aa74bf6874448be8655dab78ec4af4c"
            ]
          }
        },
        "6150b47362c644baa5c6a8391038cc3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1cc1cf2e9cc4a90aae2e74d29fb06f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42d7075988dc450e80b3322e68a151ef",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8337375fc6b14faa8c6a709568a18aa8"
          }
        },
        "8aa74bf6874448be8655dab78ec4af4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1cc26bfe5f96441c9ee216f1cfcc802d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 57.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a0e3a338a1c42cb81c38d1f2ccb307f"
          }
        },
        "42d7075988dc450e80b3322e68a151ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8337375fc6b14faa8c6a709568a18aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cc26bfe5f96441c9ee216f1cfcc802d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a0e3a338a1c42cb81c38d1f2ccb307f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fawazshah/News-Media-Reliability/blob/master/train_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v3OZRfOXciF"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WdkCXGSlBCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62da7d53-073a-4a33-bb6d-39da63d5a132"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\r\u001b[K     |▏                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 32.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 20.3MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 23.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 23.2MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 25.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 17.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81kB 18.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 17.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102kB 16.9MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 16.9MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163kB 16.9MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 16.9MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 204kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 225kB 16.9MB/s eta 0:00:01\r\u001b[K     |████                            | 235kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 256kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 276kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 296kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 307kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 317kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 327kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 337kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 348kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 358kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 368kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 378kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 389kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 399kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 409kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 419kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 430kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 440kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 450kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 460kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 471kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 481kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 491kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 501kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 512kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 522kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 542kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 552kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 563kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 573kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 583kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 593kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 604kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 614kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 624kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 634kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 645kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 655kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 665kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 675kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 686kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 696kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 706kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 716kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 727kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 737kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 747kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 757kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 768kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 778kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 788kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 798kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 808kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 819kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 829kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 839kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 849kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 860kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 870kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 880kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 890kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 901kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 911kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 921kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 931kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 942kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 952kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 962kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 972kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 983kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 993kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 16.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=3405168ce261e27acc1fe1ef6f6473624f522abf3b5cf79c4ea420731c7babdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH89boyR8xMe"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import requests\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "import time\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvijqpDgSdrG"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acNz10pHhN2o"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOjS9Y-7hJG6"
      },
      "source": [
        "import os, sys\n",
        "\n",
        "class HiddenPrints:\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout = self._original_stdout"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdQJh_Gspywv"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ltm1AzQ5P2p"
      },
      "source": [
        "corpus_url = 'https://raw.githubusercontent.com/fawazshah/News-Media-Reliability/master/data/emnlp18/corpus-modified.tsv'\n",
        "\n",
        "corpus = pd.read_csv(corpus_url, sep='\\t')\n",
        "urls = corpus['source_url_normalized'].values\n",
        "\n",
        "# Ground truths\n",
        "biases = corpus['bias'].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aljGD_19QdV"
      },
      "source": [
        "article_data_json_url = 'https://raw.githubusercontent.com/fawazshah/News-Media-Reliability/master/data/scraped_articles.json'\n",
        "\n",
        "r = requests.get(article_data_json_url)\n",
        "article_data = r.json()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcqkrRXyw58K"
      },
      "source": [
        "all_data_df = pd.DataFrame(columns=['article headline', 'article body', 'bias'])\n",
        "\n",
        "news_sources_scraped = 0\n",
        "\n",
        "for row in corpus.itertuples():\n",
        "    url = row.source_url_normalized\n",
        "    bias = row.bias\n",
        "    if article_data[\"newspapers\"][url] is not None:\n",
        "        articles = article_data[\"newspapers\"][url].get(\"articles\", [])\n",
        "        if len(articles) > 0:\n",
        "            news_sources_scraped += 1\n",
        "            for article in articles:\n",
        "                all_data_df = all_data_df.append({'article headline': article['title'],\n",
        "                                                  'article body': article['text'],\n",
        "                                                  'bias': bias}, ignore_index=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "o8iAM1Mb1-Mr",
        "outputId": "7434d863-30eb-40dc-8471-e3609e5fa84c"
      },
      "source": [
        "all_data_df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>On the Ground at the Inauguration: The Only Th...</td>\n",
              "      <td>Will Sennott\\n\\nWEDNESDAY, JANUARY 20, 2021, W...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Under President Biden, Will the Yankees Return...</td>\n",
              "      <td>Thurman Munson and Reggie Jackson in 1977 From...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gun Rights Absolutists Celebrate Martin Luther...</td>\n",
              "      <td>Will Sennott\\n\\nMONDAY, JANUARY 18, 2021, RICH...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thugs in Blue</td>\n",
              "      <td>THE BEAT GOES ON … AND ON\\n\\nOnce Again, Polic...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HELL YEAH! Sheriff Clark Publicly DISEMBOWELS ...</td>\n",
              "      <td>Al Sharpton always has had a couple screws loo...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1649</th>\n",
              "      <td>UK Educators Rank-and-File Safety Committee di...</td>\n",
              "      <td>The UK Educators Rank-and-File Safety Committe...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650</th>\n",
              "      <td>Make It Sing</td>\n",
              "      <td>Before I lay into the Democrats for missed opp...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1651</th>\n",
              "      <td>Bill Maher: The SPIN Interview</td>\n",
              "      <td>If you care at all about democracy and the way...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1652</th>\n",
              "      <td>Stephan Jenkins on What Culture Truly Means</td>\n",
              "      <td>“When bad men combine, the good must associate...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1653</th>\n",
              "      <td>Emergence Is Interactive: A Jeff Bridges and S...</td>\n",
              "      <td>Jeff Bridges is an Academy Award-winning actor...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1654 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       article headline  ...   bias\n",
              "0     On the Ground at the Inauguration: The Only Th...  ...   left\n",
              "1     Under President Biden, Will the Yankees Return...  ...   left\n",
              "2     Gun Rights Absolutists Celebrate Martin Luther...  ...   left\n",
              "3                                         Thugs in Blue  ...   left\n",
              "4     HELL YEAH! Sheriff Clark Publicly DISEMBOWELS ...  ...  right\n",
              "...                                                 ...  ...    ...\n",
              "1649  UK Educators Rank-and-File Safety Committee di...  ...   left\n",
              "1650                                       Make It Sing  ...   left\n",
              "1651                     Bill Maher: The SPIN Interview  ...   left\n",
              "1652        Stephan Jenkins on What Culture Truly Means  ...   left\n",
              "1653  Emergence Is Interactive: A Jeff Bridges and S...  ...   left\n",
              "\n",
              "[1654 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3tI0VYup1RN"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx8wTRfPI5jm",
        "outputId": "c25411e3-b910-4f71-a85a-bdaea15417ac"
      },
      "source": [
        "# Text preprocessing preparation\n",
        "\n",
        "stop_words = [\"the\", \"a\", \"an\", \"as\", \"this\", \"that\", \"is\", \"and\", \"or\", \"on\",\n",
        "              \"at\", \"to\", \"in\", \"by\", \"than\", \"of\", \"for\", \"be\", \"i\", \"you\", \n",
        "              \"he\", \"she\", \"his\", \"her\", \"do\", \"it\", \"with\"]\n",
        "\n",
        "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:          \n",
        "        return None\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# required for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# required for POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_vUJWRoo8uy"
      },
      "source": [
        "# Text preprocessing performed on both article headline and article body\n",
        "\n",
        "def preprocess(sentence):\n",
        "\n",
        "    # Lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # Punctuation, whitespace removal\n",
        "    punctuations = '''!()-—[]{};:'\"“”‘’\\,<>./?@#$%^&*_~'''\n",
        "    whitespace = '''\\n\\t'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in punctuations: \n",
        "            sentence = sentence.replace(ch, \"\")\n",
        "        if ch in whitespace:\n",
        "            sentence = sentence.replace(ch, \" \")\n",
        "\n",
        "    # Stop word removal\n",
        "    remaining_words = []\n",
        "    \n",
        "    for word in sentence.split():\n",
        "        if word not in stop_words:\n",
        "            remaining_words.append(word)\n",
        "\n",
        "    sentence = \" \".join(remaining_words)\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_words = []\n",
        "\n",
        "    # In order to lemmatise we must first POS-tag each sentence\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    for word, tag in tagged:\n",
        "        pos = nltk_tag_to_wordnet_tag(tag) \n",
        "        if pos is not None:\n",
        "            word = lemmatizer.lemmatize(word, pos=pos)\n",
        "\n",
        "        lemmatized_words.append(word)\n",
        "\n",
        "    sentence = \" \".join(lemmatized_words)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U6E9s6rRbxK",
        "outputId": "c6e52f8b-fd2a-4209-a4a2-d35c76242265"
      },
      "source": [
        "start = time.time()\n",
        "all_data_df['article headline'] = all_data_df['article headline'].apply(preprocess)\n",
        "print(f\"Preprocessing headlines took {time.time() - start} seconds\")\n",
        "\n",
        "start = time.time()\n",
        "all_data_df['article body'] = all_data_df['article body'].apply(preprocess)\n",
        "print(f\"Preprocessing article bodies took {time.time() - start} seconds\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing headlines took 2.4634039402008057 seconds\n",
            "Preprocessing article bodies took 48.547935485839844 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q95veuSydbIW"
      },
      "source": [
        "# Encode labels as numbers\n",
        "# center == 0\n",
        "# left == 1\n",
        "# right == 2\n",
        "\n",
        "def encode_labels(label):\n",
        "    if label == \"center\":\n",
        "        return 0\n",
        "    elif label == \"left\":\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "all_data_df['bias'] = all_data_df['bias'].apply(encode_labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGgA4zrUes86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5074dff-135a-464f-eae9-ea0aa9546354"
      },
      "source": [
        "all_data_df['bias'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    657\n",
              "0    567\n",
              "1    430\n",
              "Name: bias, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "nlw6MBB_lsoV",
        "outputId": "af6353b4-9199-4744-b9a2-100b0c02b6f6"
      },
      "source": [
        "# Randomly shuffle rows in dataset before splitting into folds\n",
        "all_data_df = all_data_df.sample(frac=1, random_state=1)\n",
        "all_data_df.reset_index(drop=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bidens america one nation us versus them</td>\n",
              "      <td>president joe biden sworn 46th president janua...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how get covid19 vaccine miamidade broward</td>\n",
              "      <td>keep new time free support us local community ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>arm mob storm capitol building during electora...</td>\n",
              "      <td>day will go down infamy arm mob storm united s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frontier ebook release january 2021</td>\n",
              "      <td>download month new release include late specia...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>change date vaccine news angry cricket coach</td>\n",
              "      <td>clancy overell wendell hussey kick off another...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1649</th>\n",
              "      <td>legal liability loom orgs behind rally incite ...</td>\n",
              "      <td>legal liability loom orgs behind rally incite ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650</th>\n",
              "      <td>merck france pasteur institute end development...</td>\n",
              "      <td>covid19 pandemic underscore need our company o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1651</th>\n",
              "      <td>anthony mackie responsibility message captain ...</td>\n",
              "      <td>anthony mackie clear not all say he new captai...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1652</th>\n",
              "      <td>union just get rare bit good news from supreme...</td>\n",
              "      <td>supreme court announce monday will not hear bl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1653</th>\n",
              "      <td>florida new hq maga movement</td>\n",
              "      <td>former president donald trump remain iffy 2024...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1654 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       article headline  ... bias\n",
              "0              bidens america one nation us versus them  ...    2\n",
              "1             how get covid19 vaccine miamidade broward  ...    1\n",
              "2     arm mob storm capitol building during electora...  ...    1\n",
              "3                   frontier ebook release january 2021  ...    0\n",
              "4          change date vaccine news angry cricket coach  ...    0\n",
              "...                                                 ...  ...  ...\n",
              "1649  legal liability loom orgs behind rally incite ...  ...    1\n",
              "1650  merck france pasteur institute end development...  ...    0\n",
              "1651  anthony mackie responsibility message captain ...  ...    1\n",
              "1652  union just get rare bit good news from supreme...  ...    1\n",
              "1653                       florida new hq maga movement  ...    2\n",
              "\n",
              "[1654 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCS4LqNqpw-0"
      },
      "source": [
        "### Splitting data into folds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WVsMZJip6pD"
      },
      "source": [
        "# 5 folds, each with 70% training, 10% validation, 20% train\n",
        "\n",
        "num_folds = 5\n",
        "\n",
        "fold_size = round(len(all_data_df) / num_folds)\n",
        "fold_dfs = [all_data_df.iloc[i*fold_size:(i+1)*fold_size].copy() for i in range(num_folds)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcLgT3JPrI5l"
      },
      "source": [
        "folds = {}\n",
        "\n",
        "for i, df in enumerate(fold_dfs):\n",
        "    folds[i] = {}\n",
        "    split_point_1 = int(0.7*len(df))\n",
        "    split_point_2 = int(0.8*len(df))\n",
        "    folds[i][\"train_df\"] = df.iloc[:split_point_1].copy()\n",
        "    folds[i][\"val_df\"] = df.iloc[split_point_1:split_point_2].copy()\n",
        "    folds[i][\"test_df\"] = df.iloc[split_point_2:].copy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv18NbamsoT8",
        "outputId": "5d7b4b54-4eb1-4437-eb6e-4c2283794aeb"
      },
      "source": [
        "print(f\"Number of folds: {num_folds}\")\n",
        "print(f\"Size of each training set: {len(folds[0]['train_df'])}\")\n",
        "print(f\"Size of each validation set: {len(folds[0]['val_df'])}\")\n",
        "print(f\"Size of each test set: {len(folds[0]['test_df'])}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of folds: 5\n",
            "Size of each training set: 231\n",
            "Size of each validation set: 33\n",
            "Size of each test set: 67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRvLmb5gjsqW"
      },
      "source": [
        "### BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-qdjK0sTCvE"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noOaI7TwFfO2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ffbe8eb2faad4b50afa48ac768cf1ab0",
            "21f02fd6038749d3bd7a8aeb61507f2a",
            "4432b868ea6c4bdcbdf3b00501ef5578",
            "aacc0644b7f54960bc59a268ef1e9db0",
            "e190904fd1af47b58b1a29a851bc2fe3",
            "e78d0ef5ddbc4084babcd93fbad5e286",
            "02efdba765f44740a88adec3be2ef57b",
            "98da849b315f4a9198f507279c162759"
          ]
        },
        "outputId": "cbaa6cba-38e6-4ed9-99d5-c87c88d4a96c"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffbe8eb2faad4b50afa48ac768cf1ab0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdMOKYheI2rI"
      },
      "source": [
        "# Compute the length of the longest sentence in particular column out of\n",
        "# all train, val and test data\n",
        "def compute_max_length(col_to_encode):\n",
        "\n",
        "  sentences = all_data_df[col_to_encode].values\n",
        "\n",
        "  max_len = 0\n",
        "\n",
        "  for sent in sentences:\n",
        "\n",
        "      # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "      input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "      # Update the maximum sentence length.\n",
        "      max_len = max(max_len, len(input_ids))\n",
        "\n",
        "  return max_len"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLUvQg9tJkxL",
        "outputId": "71feaca2-36b4-4e74-9f12-5c6ba3d68861"
      },
      "source": [
        "max_len_headline = compute_max_length('article headline')\n",
        "max_len_body = compute_max_length('article body')\n",
        "\n",
        "print(f\"Max headline length across all folds: {max_len_headline}\")\n",
        "print(f\"Max article body length across all folds: {max_len_body}\")\n",
        "\n",
        "if max_len_headline > 512:\n",
        "    max_len_headline = 512\n",
        "if max_len_body > 512:\n",
        "    max_len_body = 512"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max headline length across all folds: 103\n",
            "Max article body length across all folds: 14373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47kpzdncrYs_"
      },
      "source": [
        "def create_bert_dataset(df, col_to_encode, max_sequence_len):\n",
        "    # Returns a TensorDataset of sequences in col_to_encode column of df\n",
        "\n",
        "    token_ids = []\n",
        "    token_type_ids = [] # segment ids \n",
        "    attention_masks = []\n",
        "\n",
        "    sentences = df[col_to_encode].values.tolist()\n",
        "    for sent in sentences:\n",
        "        encoding_dict = tokenizer(sent,\n",
        "                                  add_special_tokens=True,\n",
        "                                  max_length=max_sequence_len,\n",
        "                                  padding='max_length',\n",
        "                                  truncation=True,\n",
        "                                  return_token_type_ids = True,\n",
        "                                  return_attention_mask = True,\n",
        "                                  return_tensors = 'pt'\n",
        "                                  )\n",
        "        token_ids.append(encoding_dict['input_ids'])\n",
        "        token_type_ids.append(encoding_dict['token_type_ids'])\n",
        "        attention_masks.append(encoding_dict['attention_mask'])\n",
        "    \n",
        "    token_ids = torch.cat(token_ids, dim=0)\n",
        "    token_type_ids = torch.cat(token_type_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(df['bias'].values)\n",
        "    \n",
        "    return TensorDataset(token_ids, token_type_ids, attention_masks, labels)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xefnAsZO59ZV"
      },
      "source": [
        "dataloaders = {}\n",
        "batch_size = 10\n",
        "\n",
        "# Note we manually shuffled the dataset earlier, so we can use SequentialSampler to\n",
        "# sample instead of RandomSampler during training\n",
        "\n",
        "dataloaders['headlines'] = {}\n",
        "for i in range(num_folds):\n",
        "    dataloaders['headlines'][i] = {}\n",
        "    train_dataset = create_bert_dataset(folds[i]['train_df'], 'article headline', max_len_headline)\n",
        "    dataloaders['headlines'][i]['train'] = DataLoader(train_dataset, sampler=SequentialSampler(train_dataset), batch_size=batch_size)\n",
        "    val_dataset = create_bert_dataset(folds[i]['val_df'], 'article headline', max_len_headline)\n",
        "    dataloaders['headlines'][i]['val'] = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n",
        "    test_dataset = create_bert_dataset(folds[i]['test_df'], 'article headline', max_len_headline)\n",
        "    dataloaders['headlines'][i]['test'] = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
        "\n",
        "dataloaders['bodies'] = {}\n",
        "for i in range(num_folds):\n",
        "    dataloaders['bodies'][i] = {}\n",
        "    train_dataset = create_bert_dataset(folds[i]['train_df'], 'article body', max_len_body)\n",
        "    dataloaders['bodies'][i]['train'] = DataLoader(train_dataset, sampler=SequentialSampler(train_dataset), batch_size=batch_size)\n",
        "    val_dataset = create_bert_dataset(folds[i]['val_df'], 'article body', max_len_body)\n",
        "    dataloaders['bodies'][i]['val'] = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n",
        "    test_dataset = create_bert_dataset(folds[i]['test_df'], 'article body', max_len_body)\n",
        "    dataloaders['bodies'][i]['test'] = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uysrdNBJx0G"
      },
      "source": [
        "def train_BERT(train_dataloader, val_dataloader, model, number_epoch):\n",
        "\n",
        "    train_loss = []\n",
        "    valid_loss = []\n",
        "\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                    lr = 2e-5, \n",
        "                    eps = 1e-8 \n",
        "                )\n",
        "\n",
        "    # Create the learning rate scheduler.\n",
        "    total_steps = len(train_dataloader) * number_epoch\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "\n",
        "        # TRAINING\n",
        "\n",
        "        time0 = time.time()\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        epoch_train_loss = 0\n",
        "        no_observations = 0\n",
        "        epoch_train_predictions = []\n",
        "        epoch_train_labels = []\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "            # Each batch contains token ids, token type ids, attention masks and labels\n",
        "            b_token_ids = batch[0].to(device)\n",
        "            b_token_type_ids = batch[1].to(device)\n",
        "            b_attention_masks = batch[2].to(device)\n",
        "            b_labels = batch[3].to(device)\n",
        "\n",
        "            no_observations = no_observations + b_labels.shape[0]\n",
        "            \n",
        "            output = model(b_token_ids, \n",
        "                    token_type_ids=b_token_type_ids, \n",
        "                    attention_mask=b_attention_masks, \n",
        "                    labels=b_labels)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            loss = output.loss\n",
        "            logits = output.logits\n",
        "\n",
        "            predictions = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "            labels = b_labels.detach().cpu().numpy()\n",
        "            epoch_train_predictions.extend(predictions)\n",
        "            epoch_train_labels.extend(labels)\n",
        "\n",
        "            loss.backward()\n",
        "            # Clip the norm of the gradients to 1 to prevent exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step() \n",
        "\n",
        "            # Update the learning rate using the scheduler\n",
        "            scheduler.step()  \n",
        "\n",
        "            epoch_train_loss += loss.item()*b_labels.shape[0]\n",
        "\n",
        "        epoch_train_loss, epoch_train_acc = epoch_train_loss / no_observations, accuracy_score(epoch_train_labels, epoch_train_predictions)\n",
        "\n",
        "        # VALIDATION\n",
        "\n",
        "        epoch_valid_loss, epoch_val_predictions, epoch_val_labels = evaluate_BERT(val_dataloader, model)\n",
        "        epoch_valid_acc = accuracy_score(epoch_val_labels, epoch_val_predictions)\n",
        "\n",
        "        # FINALLY\n",
        "\n",
        "        print(f\"Epoch took: {time.time() - time0}\")\n",
        "\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_train_loss:.2f} | Train Accuracy: {epoch_train_acc:.2f} | \\\n",
        "        Val. Loss: {epoch_valid_loss:.2f} | Val. Accuracy: {epoch_valid_acc:.2f} |')\n",
        "\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        valid_loss.append(epoch_valid_loss)\n",
        "    \n",
        "    return train_loss, valid_loss"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxb6dGkmRLky"
      },
      "source": [
        "def evaluate_BERT(test_dataloader, model):\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    no_observations = 0\n",
        "    predictions_all = []\n",
        "    labels_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            b_token_ids = batch[0].to(device)\n",
        "            b_token_type_ids = batch[1].to(device)\n",
        "            b_attention_masks = batch[2].to(device)\n",
        "            b_labels = batch[3].to(device)\n",
        "\n",
        "            no_observations += b_labels.shape[0]\n",
        "            output = model(b_token_ids, token_type_ids=b_token_type_ids, \n",
        "                                        attention_mask=b_attention_masks)\n",
        "            logits = output.logits\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "\n",
        "            predictions = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "            labels = b_labels.detach().cpu().numpy()\n",
        "            predictions_all.extend(predictions)\n",
        "            labels_all.extend(labels)\n",
        "\n",
        "            total_loss += loss.item()*b_labels.shape[0]\n",
        "    \n",
        "    return total_loss / no_observations, predictions_all, labels_all"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1d6de272bc3b4b9d8d64a44cbcd5f266",
            "b310a445d5d147c1a5ebadafecf5b6f7",
            "a4ae115b3c694b9ebe5c3573d52a2651",
            "a65df974359e47a8b8273934ea00aeaf",
            "4ba493ea05d24a2a95f0a385efbcdcda",
            "f3fe16931764493aaecbf31e18b62245",
            "bba7a6b2be794e8e9a2f732e1e69e640",
            "4b0d83d8d0f344ac8c1dd827635336eb",
            "4720716c0f7e4eeb9f0b3fac4ad68d5f",
            "6150b47362c644baa5c6a8391038cc3e",
            "c1cc1cf2e9cc4a90aae2e74d29fb06f4",
            "8aa74bf6874448be8655dab78ec4af4c",
            "42d7075988dc450e80b3322e68a151ef",
            "8337375fc6b14faa8c6a709568a18aa8",
            "1cc26bfe5f96441c9ee216f1cfcc802d",
            "2a0e3a338a1c42cb81c38d1f2ccb307f"
          ]
        },
        "id": "n-AFqf9cQIfz",
        "outputId": "a99d3770-d464-4278-8315-86016ad13f5e"
      },
      "source": [
        "num_epochs = 5\n",
        "\n",
        "data_types = ['headlines', 'bodies']\n",
        "\n",
        "for data_type in data_types:\n",
        "    for i in range(num_folds):\n",
        "\n",
        "        print(f\"-------------------\")\n",
        "        print(f\"{data_type.upper()} - FOLD {i}\")\n",
        "        print(f\"-------------------\")\n",
        "\n",
        "        # Set up a new BERT model\n",
        "        model = BertForSequenceClassification.from_pretrained(\n",
        "            'bert-base-uncased',\n",
        "            num_labels=3,\n",
        "            output_attentions = False,\n",
        "            output_hidden_states = False,\n",
        "        )\n",
        "        model.cuda()\n",
        "\n",
        "        # Train model\n",
        "        train_dataloader = dataloaders[data_type][i]['train']\n",
        "        val_dataloader = dataloaders[data_type][i]['val']\n",
        "        train_loss, valid_loss = train_BERT(train_dataloader, val_dataloader, model, num_epochs)\n",
        "\n",
        "        # Test model\n",
        "        test_dataloader = dataloaders[data_type][i]['test']\n",
        "        _, predictions, labels = evaluate_BERT(test_dataloader, model)\n",
        "\n",
        "        print(classification_report(labels, predictions))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------\n",
            "BODIES - FOLD 0\n",
            "-------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d6de272bc3b4b9d8d64a44cbcd5f266",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4720716c0f7e4eeb9f0b3fac4ad68d5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch took: 22.490711212158203\n",
            "| Epoch: 01 | Train Loss: 1.10 | Train Accuracy: 0.32 |         Val. Loss: 1.06 | Val. Accuracy: 0.39 |\n",
            "Epoch took: 23.127153873443604\n",
            "| Epoch: 02 | Train Loss: 1.05 | Train Accuracy: 0.49 |         Val. Loss: 1.00 | Val. Accuracy: 0.52 |\n",
            "Epoch took: 24.015539169311523\n",
            "| Epoch: 03 | Train Loss: 0.94 | Train Accuracy: 0.61 |         Val. Loss: 0.91 | Val. Accuracy: 0.64 |\n",
            "Epoch took: 24.676507711410522\n",
            "| Epoch: 04 | Train Loss: 0.84 | Train Accuracy: 0.64 |         Val. Loss: 0.93 | Val. Accuracy: 0.55 |\n",
            "Epoch took: 25.383132934570312\n",
            "| Epoch: 05 | Train Loss: 0.78 | Train Accuracy: 0.69 |         Val. Loss: 0.89 | Val. Accuracy: 0.67 |\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.75      0.64        24\n",
            "           1       0.17      0.06      0.09        16\n",
            "           2       0.59      0.63      0.61        27\n",
            "\n",
            "    accuracy                           0.54        67\n",
            "   macro avg       0.44      0.48      0.45        67\n",
            "weighted avg       0.48      0.54      0.50        67\n",
            "\n",
            "-------------------\n",
            "BODIES - FOLD 1\n",
            "-------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch took: 25.895670890808105\n",
            "| Epoch: 01 | Train Loss: 1.10 | Train Accuracy: 0.39 |         Val. Loss: 1.07 | Val. Accuracy: 0.42 |\n",
            "Epoch took: 26.957318782806396\n",
            "| Epoch: 02 | Train Loss: 1.05 | Train Accuracy: 0.48 |         Val. Loss: 1.05 | Val. Accuracy: 0.42 |\n",
            "Epoch took: 27.881797075271606\n",
            "| Epoch: 03 | Train Loss: 1.00 | Train Accuracy: 0.52 |         Val. Loss: 1.03 | Val. Accuracy: 0.48 |\n",
            "Epoch took: 27.207622289657593\n",
            "| Epoch: 04 | Train Loss: 0.92 | Train Accuracy: 0.56 |         Val. Loss: 1.00 | Val. Accuracy: 0.52 |\n",
            "Epoch took: 27.219014406204224\n",
            "| Epoch: 05 | Train Loss: 0.86 | Train Accuracy: 0.64 |         Val. Loss: 0.99 | Val. Accuracy: 0.52 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.54      0.54        24\n",
            "           1       0.00      0.00      0.00        17\n",
            "           2       0.42      0.69      0.52        26\n",
            "\n",
            "    accuracy                           0.46        67\n",
            "   macro avg       0.32      0.41      0.35        67\n",
            "weighted avg       0.36      0.46      0.40        67\n",
            "\n",
            "-------------------\n",
            "BODIES - FOLD 2\n",
            "-------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch took: 27.586952924728394\n",
            "| Epoch: 01 | Train Loss: 1.12 | Train Accuracy: 0.30 |         Val. Loss: 1.09 | Val. Accuracy: 0.39 |\n",
            "Epoch took: 27.75044083595276\n",
            "| Epoch: 02 | Train Loss: 1.06 | Train Accuracy: 0.45 |         Val. Loss: 1.06 | Val. Accuracy: 0.42 |\n",
            "Epoch took: 27.32691526412964\n",
            "| Epoch: 03 | Train Loss: 0.93 | Train Accuracy: 0.59 |         Val. Loss: 1.07 | Val. Accuracy: 0.45 |\n",
            "Epoch took: 27.473117113113403\n",
            "| Epoch: 04 | Train Loss: 0.88 | Train Accuracy: 0.61 |         Val. Loss: 1.08 | Val. Accuracy: 0.42 |\n",
            "Epoch took: 27.62786078453064\n",
            "| Epoch: 05 | Train Loss: 0.82 | Train Accuracy: 0.62 |         Val. Loss: 1.09 | Val. Accuracy: 0.48 |\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.40      0.40        20\n",
            "           1       0.00      0.00      0.00        22\n",
            "           2       0.38      0.72      0.50        25\n",
            "\n",
            "    accuracy                           0.39        67\n",
            "   macro avg       0.26      0.37      0.30        67\n",
            "weighted avg       0.26      0.39      0.31        67\n",
            "\n",
            "-------------------\n",
            "BODIES - FOLD 3\n",
            "-------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch took: 27.313726663589478\n",
            "| Epoch: 01 | Train Loss: 1.11 | Train Accuracy: 0.37 |         Val. Loss: 1.06 | Val. Accuracy: 0.42 |\n",
            "Epoch took: 27.415733098983765\n",
            "| Epoch: 02 | Train Loss: 1.06 | Train Accuracy: 0.45 |         Val. Loss: 1.05 | Val. Accuracy: 0.52 |\n",
            "Epoch took: 27.208957195281982\n",
            "| Epoch: 03 | Train Loss: 1.02 | Train Accuracy: 0.51 |         Val. Loss: 1.01 | Val. Accuracy: 0.55 |\n",
            "Epoch took: 27.156667470932007\n",
            "| Epoch: 04 | Train Loss: 0.96 | Train Accuracy: 0.60 |         Val. Loss: 0.99 | Val. Accuracy: 0.48 |\n",
            "Epoch took: 27.298508405685425\n",
            "| Epoch: 05 | Train Loss: 0.91 | Train Accuracy: 0.62 |         Val. Loss: 0.97 | Val. Accuracy: 0.58 |\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.68      0.64        25\n",
            "           1       0.00      0.00      0.00        17\n",
            "           2       0.56      0.88      0.69        25\n",
            "\n",
            "    accuracy                           0.58        67\n",
            "   macro avg       0.39      0.52      0.44        67\n",
            "weighted avg       0.44      0.58      0.50        67\n",
            "\n",
            "-------------------\n",
            "BODIES - FOLD 4\n",
            "-------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch took: 27.27707052230835\n",
            "| Epoch: 01 | Train Loss: 1.08 | Train Accuracy: 0.42 |         Val. Loss: 1.08 | Val. Accuracy: 0.44 |\n",
            "Epoch took: 27.4079692363739\n",
            "| Epoch: 02 | Train Loss: 1.00 | Train Accuracy: 0.52 |         Val. Loss: 1.07 | Val. Accuracy: 0.47 |\n",
            "Epoch took: 27.26679754257202\n",
            "| Epoch: 03 | Train Loss: 0.86 | Train Accuracy: 0.61 |         Val. Loss: 1.06 | Val. Accuracy: 0.50 |\n",
            "Epoch took: 27.19868493080139\n",
            "| Epoch: 04 | Train Loss: 0.74 | Train Accuracy: 0.68 |         Val. Loss: 1.11 | Val. Accuracy: 0.44 |\n",
            "Epoch took: 27.107280254364014\n",
            "| Epoch: 05 | Train Loss: 0.67 | Train Accuracy: 0.72 |         Val. Loss: 1.09 | Val. Accuracy: 0.47 |\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.48      0.56        33\n",
            "           1       0.40      0.15      0.22        13\n",
            "           2       0.43      0.80      0.56        20\n",
            "\n",
            "    accuracy                           0.52        66\n",
            "   macro avg       0.50      0.48      0.45        66\n",
            "weighted avg       0.54      0.52      0.49        66\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ponCV4YPQ0gl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}